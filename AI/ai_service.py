# ai_service.py
from openai import OpenAI
import os
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. í…ìŠ¤íŠ¸ -> ë²¡í„° ë³€í™˜ (ì„ë² ë”©)
def get_embedding(text):
    text = text.replace("\n", " ")
    response = client.embeddings.create(input=[text], model="text-embedding-3-small")
    return response.data[0].embedding

# 2. ì „ì‹œíšŒ ì¶”ì²œ ë¡œì§
def recommend_exhibitions(user_tags, exhibition_list):
    """
    user_tags: "í™í•œ ì„±ìˆ˜ë™ ë°ì´íŠ¸"
    exhibition_list: ìˆ˜ì§‘í•œ ì „ì‹œíšŒ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ¤– ì¶”ì²œ ë¶„ì„ ì‹œì‘: {user_tags}")
    
    # ì‚¬ìš©ì ì·¨í–¥ ë²¡í„°í™”
    user_vec = get_embedding(user_tags)
    
    scored_list = []
    for exh in exhibition_list:
        # ì „ì‹œíšŒ ì •ë³´ ë²¡í„°í™” (ì œëª©+ì¥ì†Œ í…ìŠ¤íŠ¸ ì´ìš©)
        # *ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  DBì— ë¯¸ë¦¬ ë²¡í„°ê°’ì„ ì €ì¥í•´ë†”ì•¼ ë¹ ë¦„*
        exh_vec = get_embedding(exh['desc'])
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        score = cosine_similarity([user_vec], [exh_vec])[0][0]
        exh['score'] = score
        scored_list.append(exh)
    
    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬ í›„ Top 3 ë°˜í™˜
    scored_list.sort(key=lambda x: x['score'], reverse=True)
    return scored_list[:3]

# 3. AI ë„ìŠ¨íŠ¸ (TTS)
def generate_docent_audio(text, style="kind"):
    print(f"ğŸ¤ ì˜¤ë””ì˜¤ ìƒì„± ì¤‘... ìŠ¤íƒ€ì¼: {style}")
    
    # í˜ë¥´ì†Œë‚˜ ì„¤ì •
    system_prompt = "ë„ˆëŠ” ì¹œì ˆí•œ ë¯¸ìˆ ê´€ ë„ìŠ¨íŠ¸ì•¼."
    voice_model = "nova" # ì—¬ì„±í†¤ (kind)
    
    if style == "funny":
        system_prompt = "ë„ˆëŠ” ì•„ì£¼ ì¬ë°Œê³  ìœ ì¾Œí•œ ì¹œêµ¬ ê°™ì€ ë„ìŠ¨íŠ¸ì•¼."
        voice_model = "onyx" # ë‚¨ì„±í†¤
        
    # ëŒ€ë³¸ ë‹¤ë“¬ê¸° (GPT)
    gpt_res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ì´ ì‘í’ˆ ì„¤ëª…í•´ì¤˜: {text}"}
        ]
    )
    script = gpt_res.choices[0].message.content
    
    # ì˜¤ë””ì˜¤ ìƒì„± (TTS)
    audio_res = client.audio.speech.create(
        model="tts-1",
        voice=voice_model,
        input=script
    )
    
    filename = f"docent_{style}.mp3"
    audio_res.stream_to_file(filename)
    return filename

# 4. ë°ì´íŠ¸ ì½”ìŠ¤ ì§œì£¼ê¸°
def generate_course_text(exhibition, location, who):
    prompt = f"""
    ë©”ì¸ ì „ì‹œ: {exhibition}
    ìœ„ì¹˜: {location}
    ë™í–‰: {who}
    
    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {who}ê³¼ í•¨ê»˜í•˜ê¸° ì¢‹ì€ 'ì „ì‹œ ë‚˜ë“¤ì´ ì½”ìŠ¤'ë¥¼ ì¶”ì²œí•´ì¤˜.
    [ì‹ì‚¬] -> [ì „ì‹œ ê´€ëŒ] -> [ì¹´í˜] ìˆœì„œë¡œ ì‹¤ì œ {location}ì˜ ë§›ì§‘ì„ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜.
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content